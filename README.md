ğŸ¤– AI QA Chatbot with LangChain, LangGraph & FastAPI

A scalable and extensible AI-powered Question Answering (QA) Chatbot built using LangChain, LangGraph, and FastAPI.
It supports document ingestion, retrieval-augmented generation (RAG), vector-based search, and stateful conversation agents, accessible via both REST API and CLI interface.

ğŸš€ Features

ğŸ“„ PDF Upload & Ingestion â€“ Extracts and chunks text from PDF documents

ğŸ§  RAG (Retrieval-Augmented Generation) â€“ Combines document retrieval with LLM reasoning

ğŸ—‚ï¸ Vector Database Integration â€“ Stores embeddings using PostgreSQL with pgvector extension

âš™ï¸ LangChain + LangGraph Agents â€“ Handles conversational memory and reasoning graph orchestration

ğŸŒ FastAPI Endpoints â€“ For document management and query handling

ğŸ’¬ Interactive CLI Client â€“ Chat directly with your AI assistant

ğŸ” Secure Configuration â€“ Environment-based credentials management

ğŸ§© Modular & Extensible Design â€“ Easy to customize or extend components

ğŸªµ Comprehensive Logging â€“ Logs for API, vectorstore, and agent responses

ğŸ—ï¸ Architecture
User / CLI / Frontend
        â”‚
        â–¼
[ FastAPI Backend ] â‡„ [ PostgreSQL + pgvector ]
        â”‚
        â–¼
[ LangGraph Agent + LangChain Core + Vectorstore ]
        â”‚
        â–¼
[ OpenAI or Other LLM APIs ]

ğŸ“˜ Workflow

PDFs are uploaded via API and processed asynchronously

Text is extracted, chunked, and embedded using LangChain

Embeddings are stored in PostgreSQL with pgvector

LangGraph orchestrates retrieval and conversation logic

FastAPI exposes endpoints for upload, query, and management

CLI provides lightweight local testing without HTTP overhead

âš™ï¸ Setup Instructions
ğŸ§¾ Prerequisites

ğŸ Python 3.10 or higher

ğŸ˜ PostgreSQL (with pgvector extension enabled)

ğŸ”‘ OpenAI API key (or compatible LLM provider)

ğŸ§© LangGraph API key (if applicable)

ğŸ§° Installation Steps

1. Clone the repository

git clone https://github.com/yourusername/yourrepo.git
cd yourrepo


2. Create a virtual environment

python -m venv .venv
# Activate it
source .venv/bin/activate        # macOS/Linux
.venv\Scripts\activate           # Windows


3. Install dependencies

pip install -r requirements.txt


4. Configure environment variables

Create a file named .env in the root directory:

OPENAI_API_KEY=your_openai_api_key
LANGGRAPH_API_KEY=your_langgraph_api_key
DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/yourdb


5. Enable pgvector extension in PostgreSQL

CREATE EXTENSION IF NOT EXISTS vector;


6. Start FastAPI server

uvicorn main:app --reload --port 8000


7. (Optional) Launch the CLI chatbot

python agent_cli.py

ğŸ§  Usage
ğŸŒ API Endpoints
Method	Endpoint	Description
POST	/upload	Upload and index a PDF document
POST	/ask	Query the chatbot with a question
GET	/documents	List all uploaded documents
DELETE	/documents/{id}	Delete a document by its ID

Example Query

curl -X POST "http://localhost:8000/ask" \
     -H "Content-Type: application/json" \
     -d '{"question": "What is this document about?"}'

ğŸ’¬ Interactive CLI

Run the CLI chatbot:

python agent_cli.py


ğŸªµ Logging & Debugging

All API requests, responses, and agent calls are logged with timestamps

Vectorstore logs document indexing and retrieval operations

LangGraph agent traces conversation state and LLM reasoning

Adjust logging verbosity in configuration if needed

ğŸ”’ Security

.env file contains sensitive data â€“ never commit it to Git

.gitignore excludes .env, cache, and unnecessary build files

Restrict PostgreSQL credentials and rotate API keys regularly
